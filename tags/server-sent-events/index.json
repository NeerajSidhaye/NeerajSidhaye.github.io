[{"content":"In this post, we will scan GO application code for security issues using gosec and will also integrate gosec with SonarCloud.\nWe will explore below topics\n What is gosec?\n  Installing gosec\n  Running security checks for a GO code\n  Analyzing gosec reports\n  SonarCloud Integration with gosec\n  Companies using gosec\n What is gosec? gosec is a static code analyzer tool for inspecting go application code for security problems.\nstatic code analyzer meaning - analyze code without running the application.\nGosec currently has a set of 30 rules that map to the Common Weakness Enumeration (CWE) framework. Those rules help to secure your code by covering 8 of the 2019 CWE Top 25 Most Dangerous Software Errors.\ngosec github repo\nInstalling gosec gosec can be installed using go get or using CLI.\nIf you already have go installed then run below command to install gosec.\ngo get github.com/securego/gosec/cmd/gosec\rAfter running this command, you would see gosec executable available here $GO_PATH/bin/gosec.\nIf you don\u0026rsquo;t have GO installed, you can install gosec using CLI.\nPlease have a look at gosec CLI installation options\nRunning security checks for a GO project I will be using my existing go project github repo for running gosec security checks.\nYou could create a simple go project and execute gosec.\n Running gosec from project root folder\n gosec ./...\rThis will scan all the go files located in all the packages and sub packages from the root folder.\n  Expand Me - Running gosec.    Analyzing reports You can also specify security check result to be produced in a specific format and written to a file.\n json example\n gosec -fmt=json -out=gosecResult.json ./...\rThis will generate security scan result in the mentioned json file.\n  Expand Me - gosec report.    All the supported formats.\nSonarCloud Integration gosec security result can be easily integration with SonarCloud and then we analyse result on SonarCloud.\nConfiguring project in SonarCloud We will need to configure github repo in SonarCloud and for this, we will create new project in SonarCloud and link that project to github repo and branch.\n  Expand Me- Configuring github project in SonarCloud.    Adding sonar-project.properties to the project Few important properties\nsonar.projectKey = project key of new project which we just created on the SonarCloud.\nsonar.externalIssuesReportPaths = We will generate this report in sonar supported format by using gosec command.\nsonar.projectKey=gosec_go-rest-api\rsonar.organization=bethecodewithyou-github\rsonar.host.url=https://sonarcloud.io\rsonar.sources=.\rsonar.exclusions=**/*_test.go\rsonar.externalIssuesReportPaths=gosecReport.json\rGenerate gosec report for SonarCloud gosec -fmt=sonarqube -out=gosecReport.json ./... If you notice here, we are using sonarqube format and it is one of the supported formats in gosec.\nRunning the Sonar Scanner sonar-scanner.bat \\\r-D\u0026quot;sonar.organization=bethecodewithyou-github\u0026quot; \\\r-D\u0026quot;sonar.projectKey=gosec_go-rest-api\u0026quot; \\\r-D\u0026quot;sonar.sources=.\u0026quot; \\\r-D\u0026quot;sonar.host.url=https://sonarcloud.io\u0026quot;\rAfter running this command, the results should be available on your SonarCloud server shortly.\nYou can take a look here on - downloading and configuring Sonar Scanner.\nAnalyzing gosec report on SonarCloud Now, we will analyze gosec report directly on SonarCloud.\n Companies using gosec List of companies using gosec. Sourced from here.\n Gitlab CloudBees VMware Codacy Coinbase RedHat/OpenShift Guardalis 1Password PingCAP/tidb  ","description":"Scanning GO application code with gosec for security problems. gosec is static code analysis tool for finding security issues in go application. We will also integrate gosec with SonarCloud. Let's hands on...","id":2,"section":"posts","tags":["GO","Security","SonarCloud"],"title":"gosec - Go Security scanner and gosec integration with SonarCloud","uri":"https://neerajsidhaye.com/posts/go/security/goappsecuritychecker/"},{"content":"In this post, we will be creating an optimized docker image for GO application using multi stage build - using alpine image and then produce a small image with only binary in a scratch image. Let\u0026rsquo;s read further\u0026hellip;\nAssuming that you have got docker, git and GO installed on your machine so that you can build your GO app locally and then create a docker image.\nMulti Stage Build We will be creating a multi stage build.\n First stage -\u0026gt; We will use base image as golang:alpine Alpine Linux image to build our application.\n  Second stage -\u0026gt; We will use docker scratch image - zero byte image and then our build will contain binary executable built from first stage.\n GO Application I have got a GO application running locally, which is a simple Product API built using GorillaMux and exposing 5 endpoints.\nCode for Product API is available on my github repo - GO Product API\nGET /products/\nPOST /products/\nPUT /products/{id}\nPATCH /products/{id}\nDELETE /products/{id}\nLet\u0026rsquo;s quickly build and test app locally\n1 2 3  go build product.exe   Please click on below animated gif to get better view üòé\nCreating Dockerfile Let\u0026rsquo;s create docker file with multistage build.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  FROMgolang:alpine AS builderENV GO111MODULE=on \\  CGO_ENABLED=0 \\  GOOS=linux \\  GOARCH=amd64 # move to working directory buildWORKDIR/build# copy and download dependencices with go.modCOPY go.mod .COPY go.sum .RUN go mod download# COPY the source code from current dir to working dir into the containerCOPY . .# build the applicationRUN go build -o main ./cmd/app/product/# move to /dist directory as the place for resulting binary folderWORKDIR/dist# copy binary from bulid to main folderRUN cp /build/main .# Stage 2 - building a small image from Scratch ###FROMscratch# copy the prebuilt binary from the previous stageCOPY --from=builder /dist/main /# Expose the app portEXPOSE7070# command to runENTRYPOINT [ \u0026#34;/main\u0026#34; ]  Creating Docker image I have got docker installed on OracleVM virtual box on my Windows 10 machine.\nMy setup looks like this. Please expand the section Docker setup on Oracle VM\n  Expand Me- Docker setup on Oracle VM  Below is my local Windows 10 machine running docker version command.\n  Ok, let\u0026rsquo;s build our docker image.\n1  docker build -t go-rest-gorilla-docker .   Optimized image - it is just 8.02 MB üëã\n  Image without scratch - Now, if we modify our docker file and build image without scratch, then our docker image size would be 353 MB üò°\n Running Docker image üèÉ Ok, let\u0026rsquo;s run our docker image and test the application.\n1  docker run -d -p 8080:7070 go-rest-gorilla-docker  We are now running our docker image, mapped port 8080 to our exposed port 7070.\nIf you notice, I use IP address here not localhost because, my docker is running on OracleVM box which has got it\u0026rsquo;s IP address configured as 192.168.99.100\nCode Complete code is available on my github repo here GO Rest Gorilla - Product API\n","description":"Creating optimized docker image for GO application using multi stage build - using alpine image and then produce a small image with only binary in a scratch image. Let's read further...","id":5,"section":"posts","tags":["GO","Docker"],"title":"Dockerizing GO applications","uri":"https://neerajsidhaye.com/posts/go/docker/dockerizegoapp/"},{"content":"In this post, I will show you, how simple and fast you can write automation tests for your API using ZeroCode framework\nBefore we start, let\u0026rsquo;s quickly read about Test Flavours - test types and where does ZeroCode framework fits in.\nTest Flavours   Expand - Test Flavours   Unit Tests This covers smallest piece of code which validates whether targeted code block works as expected with varieties of inputs. We use JUNIT and other mocking frameworks like Mockito etc as required.\n  Integration Tests This verifies communication paths and interaction between components and used to detect interface defects.\nFor Example:- If our application has got 3 microservices which might be consuming other external services or databases. Integration tests make sure that our application API\u0026rsquo;s are communicating well those external services as per agreed contacts.\n  Component Tests This is where we write test which cover various layers within an API as a whole component. We don\u0026rsquo;t go outside of our api boundary.\nFor example:- In this we write test for our Controllers and then the test flow goes through service layers, repository layers, gateway layers. Here we mock the api response of external api\u0026rsquo;s, because we are testing our own API component and not the external boundaries.\n  Contract Tests Verify the contracts with external boundary systems and making sure that it meets the contact expected by the consuming services.\nFor example:- Our application api\u0026rsquo;s are consuming external services and the contract with those external services meets the functionality.\n  End to end Tests As the name suggests, this verifies that the system works as expected as a whole entity from end to end - covering all internal and external components together.\n Ok, I think that pretty much covers various test flavours.\nZeroCode framework fits perfectly well for\nüëâ Integration Tests, üëâ Component Tests, üëâ Contract Tests and üëâ End to End Tets.\r  Alright cool, so if you have read about Test Flavours, then let\u0026rsquo;s get into code and find out how simple and quickly we can write tests with ZeroCode framework.\nüí• ZeroCode tests can be written for API's exposed in any language (JAVA, GO, DOT NET etc ).\rAs long the API is exposed over http, we are good to write test using ZeroCode.\r Product API We have got our Product API running locally with below end points and we will be writing ZeroCode tests for this Product API.\n  GET /products Returns list of products\n  POST /products Creates a new product\n  PUT /products/{id} Updates a product for a given product id\n  PATCH /products/{id}\nPartial updates to product for a given id\n  DELETE /products/{id}\nDeletes a product for a given product id\n  Product API running locally I have product api running on http://localhost:7070 and and it\u0026rsquo;s written in GO using Gorilla Mux library.\n  Expand - Product API  Please just click on below gif to get better view üòé\n  ZeroCode tests Steps to write ZeroCode tests.\nStep 1 - Generate test project using ArcheType Archetype is a fastest way to generate project skeleton and we can add boiler plate code with it.\nCreate a new folder ‚û°Ô∏è cd to that folder ‚û°Ô∏è copy below archetype command and just run it.\nYou should see a project ready for you with all the boiler plate code.\n mvn archetype:generate \\\r-DarchetypeGroupId=org.jsmart \\\r-DarchetypeArtifactId=zerocode-maven-archetype \\\r-DgroupId=com.ns \\\r-DartifactId=product-api-tests \\\r-Dversion=1.0.0-SNAPSHOT\rArchType - see in Action   Expand - ArchType In Action  Please just click on below gif to get better view üòé\n  Step 2 - Writing Tests Ok, Cool. We have got our project ready with dummy tests.\nNow let\u0026rsquo;s update config and tests\n  update hostconfig_ci.properties\nOpen hostconfig_ci.properties file and add url of our Product api against the key web.application.endpoint.host. I have added url of locally running Product API.\nweb.application.endpoint.host=http://localhost:7070\n #Continuous Integration Context\r# Web Server host and port\rweb.application.endpoint.host=http://localhost:7070\r# Web Service Port; Leave it blank in case it is default port i.e. 80 or 443 etc\rweb.application.endpoint.port=\r# Web Service context; Leave it blank in case you do not have a common context\rweb.application.endpoint.context=\r  Write tests cases using JSON\nWriting test for GET end point.\nFor all other endpoints tests, please have a look at the section\nWriting All Tests in Action below.\nGET /products\nOpen get_api_200.json and update below as per your api functionality.\nFor Product API, I have updated below.\n-\u0026gt; name - \u0026ldquo;get_product_detail\u0026rdquo;. It\u0026rsquo;s a step name to tell, what api we are testing.\n-\u0026gt; url - /products\n-\u0026gt; request body - left it blank here for GET request in this case\n-\u0026gt; verify status - It\u0026rsquo;s a assertion we are doing here. Verifying 200 status code.\n-\u0026gt; verify response body - Asserting that response body should have not-null id.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  { \u0026#34;scenarioName\u0026#34;: \u0026#34;Validate the GET api\u0026#34;, \u0026#34;steps\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;get_product_details\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;/products\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;request\u0026#34;: { }, \u0026#34;verify\u0026#34;: { \u0026#34;status\u0026#34;: 200, \u0026#34;body\u0026#34;:[ { \u0026#34;id\u0026#34; : \u0026#34;$IS.NOTNULL\u0026#34; } ] } } ] }     And that\u0026rsquo;s all, Our test case is ready for GET PRODUCT details.\n  Expand Me- Writing all Tests in Action  Please just click on below gif to get better view üòé\n  That\u0026rsquo;s all! We are just done with writing out tests. It just really few mins!!\nStep 3 - Running the tests Let\u0026rsquo;s run our tests. We can run test directly from IDE and from command line and from Jenkins jobs. üòé\n For integration with CI/CD pipeline, we can just create mvn or gradle tasks for our tests and configure the task in the jenkins pipeline.\n   Expand Me- Running Tests from IDE  Please just click on below gif to get better view üòé\n  Running Individual Test from command line\nmvn -Dtest=MyGetApiTest test\rRunning TestSuite from command line\nmvn -Dtest=MyApiSuite test\rCreating gradle task\ntask runProductAPITestSuite ( type : Test ) {\rdelete \u0026quot;/target/\u0026quot;\rsystemProperty 'zerocode.junit', 'gen-smart-charts-csv-reports'\rinclude 'com/ns/MyApiSuite.class\r}\rRunning the gradle task - runProductAPITestSuite\ngradle runProductAPITestSuite\rTest Reports ZeroCode generates interactive test reports.\nJust build the test project and it will run all the tests and create a report folder which will have detailed report.\nmvn clean install\r  Expand Me- Test Reports  Please just click on below gif to get better view üòé\n  I hope you like this post. Please do share your comments.\n","description":"API Test Automation should be very simple, involve less learning curve, easy to collaborate, ease of integration with CI/CD pipeline and provide a good test reports. Developer and Testers both should be able to contribute in writing tests and most importantly, they should be focusing on writing quality test cases and not wasting anytime on learning the testing tool itself. ZeroCode open source framework is a perfect fit! Let's read on...","id":6,"section":"posts","tags":["API Test Automation"],"title":"API Test Automation - in minutes!!","uri":"https://neerajsidhaye.com/posts/api/test/zerocodearchtype/"},{"content":"I am sure, how to structure a Go Project, would have been most obvious question which everybody have thought through and it is very obvious. Specially after we write some basic hello world which has only main.go or after doing workouts in Go Playground\nAs we step up and write more code which involve various layering, then it becomes very essential to organize the code, so that:-\n easy to understand and maintain each package purpose becomes self explanatory by it\u0026rsquo;s name reduce interdependencies in the code increase code reusability ease of collaboration  Well, you can think of more points, but the fact is, it is very important to follow a basic template which is set a as standard by various GO projects ( GO doesn\u0026rsquo;t provide any official docs on project structure as such) and later on top of that, one can evolve their own structure as needed.\nThis is what, I have followed so far for my basic applications in GO. I have not hit that complexity so far, as I have just started learning and writing basic applications in GO.\n/cmd/app/\u0026laquo;your app name\u0026raquo; So, on the root of your project, you will have cmd/app/\u0026laquo;your app name\u0026raquo;\nfor example If you are building product API, then could you below\n \u0026laquo;project-root\u0026raquo;/cmd/app/product/main.go\n This folder, will always have only one file, and that\u0026rsquo;s your starting point of project - main.go\n/internal As the name suggest, all files and sub folders inside internal, will be private your your application and will not be shared externally.\nfor example - you can further define sub-folders like data and handlers\n /internal/data/product.go\n/internal/handlers/product.go\n üîî internal is official: it‚Äôs the only directory named in Go‚Äôs documentation and has special compiler treatment\nüîî The other important point to note here is - in GO, you can have files with exact same name as long as they are in different package. Also, in GO, it is NOT a good practice to use naming like ProductHandlers.go. As the product.go file is defined in the handler package, it is implicit that it is handler. ‚≠ê\n/pkg You will have go files here, which are ok to be used by external applications. Other project will use these files from pkg. Mostly your public API code goes here in the pkg\n/static You could have static folder which contains static files used by your project. If files are internal to your app, then you can very well move this static folder inside internal.\nYou could have a look at very basic project structure which I have used in my repo in Go REST using Gorilla Mux\nI would also recommend to have a look at GO standard project layout\n","description":"What project structure to follow for GO projects? How to organize internal and external packages, so that things get simple and easy to collaborate. Lets read on...","id":7,"section":"posts","tags":["GO starter"],"title":"Go - Project Structure","uri":"https://neerajsidhaye.com/posts/go/starter/goprojectlayout/"},{"content":"In this post, I will try to put together notes around GO service and REST API.\n The complete source code is available on my github repo.I have created 3 branches, each branch representing different flavour of writing service.\nGO api source code\nOk, let\u0026rsquo;s go ahead\u0026hellip;\nGO - WebService GO package net/http does the job for us. It stars the sever and ready to receive request at /hello with http.HandleFun\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; ) // a simple http web service which is exposing /hello end point on port 7070. func main() { http.HandleFunc(\u0026#34;/hello\u0026#34;, func(rw http.ResponseWriter, r *http.Request) { fmt.Println(\u0026#34;hello GO http web service\u0026#34;) data, err := ioutil.ReadAll(r.Body) // r.body - reads the request body \tif err != nil { http.Error(rw, \u0026#34;error occurred\u0026#34;, http.StatusInternalServerError) return } fmt.Fprintf(rw, \u0026#34;HELLO %s\\n\u0026#34;, data) }) // http webservice will be listening on any ip address and on port 7070. \thttp.ListenAndServe(\u0026#34;:7070\u0026#34;, nil) }   I have written another web service example, where I have created a Handler and ServeMux and then registering handler to ServeMux.\nYou can have a look at the code here - getProduct service\nGo - REST API GO REST API using standard go libraries. If you see the code of below product handler, you can see I have API with methods handling GET, POST and PUT.\nThe important point you would note here is, you will have to write a lot of code to parse URI params ( in this example) when you use go standard libraries.\nSame way, there may be other scenarios when you have to keep writing code for basic boiler plate processing.\nYou can see the quick demo here\nClick for Demo \r\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  //handler is serving httpRequest. Returning product response JSON. func (p *Product) ServeHTTP(rw http.ResponseWriter, r *http.Request) { if r.Method == http.MethodGet { p.l.Println(\u0026#34;handling GET\u0026#34;) p.getProducts(rw, r) return } if r.Method == http.MethodPost { p.l.Println(\u0026#34;handling POST\u0026#34;) p.addProduct(rw, r) return } if r.Method == http.MethodPut { p.l.Println(\u0026#34;handling PUT\u0026#34;) regex := regexp.MustCompile(`/([0-9]+)`) g := regex.FindAllStringSubmatch(r.URL.Path, -1) p.l.Printf(\u0026#34;regex g group %q\\n\u0026#34;, g) // if true, means there are more than one id passed in the URI. \tif len(g)!=1 { p.l.Println(\u0026#34;invalid product id in the URI\u0026#34;) http.Error(rw, \u0026#34;Invalid Request URI\u0026#34;, http.StatusBadRequest) return } if len(g[0]) \u0026gt; 2 { http.Error(rw, \u0026#34;Invalid URI\u0026#34;, http.StatusBadRequest) return } productID := g[0][1] idString, err := strconv.Atoi(productID) if err!=nil { http.Error(rw, \u0026#34;Invalid id value in URI\u0026#34;, http.StatusBadRequest) return } p.l.Println(\u0026#34;updating product for ID -\u0026gt;\u0026#34;, idString) p.updateProduct(idString, rw, r) return } // For any other methods, we are returning method not allowed \trw.WriteHeader(http.StatusMethodNotAllowed) }   GO - REST API using Gorilla Mux Include Gorilla mux dependency to go.mod.\nGo mod is like gradle or maven where we include dependencies.\n1 2 3  require ( github.com/gorilla/mux v1.8.0 )   Include the package gorilla mux to your go file.\n1 2 3  import ( \u0026#34;github.com/gorilla/mux\u0026#34; )   And now we will just create our servMux from gorilla Mux and register our product handler with various endpoints for handling GET, POST, PUT, PATCH and DELETE.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  servMux := mux.NewRouter() // registers product handler methods to serve request on api end points with specific http methods. \tgetHandler := servMux.Methods(http.MethodGet).Subrouter() getHandler.HandleFunc(\u0026#34;/products\u0026#34;, productHandler.GetProducts) postHandler := servMux.Methods(http.MethodPost).Subrouter() postHandler.HandleFunc(\u0026#34;/products\u0026#34;, productHandler.AddProduct) putHandler := servMux.Methods(http.MethodPut).Subrouter() putHandler.HandleFunc(\u0026#34;/products/{id:[0-9]+}\u0026#34;, productHandler.UpdateProduct) patchHandler := servMux.Methods(http.MethodPatch).Subrouter() patchHandler.HandleFunc(\u0026#34;/products/{id:[0-9]+}\u0026#34;, productHandler.UpdateProductAttribute) deleteHandler := servMux.Methods(http.MethodDelete).Subrouter() deleteHandler.HandleFunc(\u0026#34;/products/{id:[0-9]+}\u0026#34;, productHandler.DeleteProduct)   If you see here, it becomes so easy to parse the UI params using gorilla mux lib\n1 2 3 4 5 6 7  //UpdateProduct : updating a product func (p *Product) UpdateProduct(rw http.ResponseWriter, r *http.Request) { p.l.Println(\u0026#34;handling UPDATE\u0026#34;) uriParams := mux.Vars(r) id, err := strconv.Atoi(uriParams[\u0026#34;id\u0026#34;])   Take a look at the repo for details about how api is working and you can simply clone it and run locally.\nGO api source code\nHope you like this short post about GO api..\n","description":"Writing API in Go with various flavours. Simple Go http web service, GO REST API using Go standard libraries and Go REST API using Gorilla Mux.","id":8,"section":"posts","tags":["GO","REST API"],"title":"Go - Building API","uri":"https://neerajsidhaye.com/posts/go/api/gorestapi/"},{"content":"I have put together my notes around some of the basic microservices design principles which we must always consider while designing a microservice.\nDesign principles for MicroServices 1. Develop and Deployed independently Each service should be developed and deployed independently. Deployment of one service should not impact other services and a each service should have it\u0026rsquo;s own code base.\nYou are doing wrong if\n You find a need to deploy services together You have one code base for multiple services You need to send notification to before you deploy a service  2. Data Ownership Service should have it\u0026rsquo;s own database or preferably set of tables that is manged by only a specific service. Should avoid scenario where multiple services are writing and reading from the same set of tables, any changes to table would require changes in all services.\nHaving each service has it\u0026rsquo;s own data ownership introduce loose coupling between service and database.\nkey point is, services should NOT have knowledge of each others underlying database.\nHaving own database for a services allows to choose right database technologies based on service functionality.\n3. Loosely coupled from all other services once you adhere to point 1 and 2, you have already initiated loose coupling but there are points to address on loose coupling:-\nminimal dependency on other services Communication with other services should be over exposed public interfaces( API, events etc ) and such interfaces or API should NOT expose internal details.\n4. Follow High Cohesion Methodology Closely related functionality must stay together in a single service. this minimizes intercommunication between services.\n5. Resilient service Single point of failure in system should NOT impact multiple services. if you have a service with independent data ownership, loose coupling, independent deployable artifact, it is a step towards resilient system!\nRemember - Total resilience in the face of all situations is NOT possible.Implement what is feasible in the short term and work to achieve greater resilience in stages.\n6. Shared Library Carefully watch out implications of shared library introduction to your services. You are doing something wrong when changes to shared library requires updates to all services simultaneously.\n7. Introduce Asynchronous Workers Very important design principle - introduce asynchronous workers to minimize impact on primary service API.\nExample -\u0026gt; A batch job can be introduced in a service as an asynchronous worker which is responsible to process high volume request, re-try mechanism for failed request etc.\nThis asynchronous worker provide following benefits:-\n Speed up the primary request path Spread load to asynchronous worker in case of high volume request Reduce error scenarios on primary API.  8. Service Versioning An API is never going to be completely stable. Change is inevitable!!\nIt\u0026rsquo;s always a best practice to version your service. Versioning can be added to header or in the service url. Following technique can be used to maintain service version:-\nThe URL has a major version number (v1), but the API has date based sub- versions which can be chosen using a custom HTTP request header. In this case, the major version provides structural stability of the API as a whole while the sub-versions accounts for smaller changes (field deprecations, endpoint changes, etc).\n","description":"Microservices at it's core is based on designing a bunch of small services based on specific business capabilities. Small service means, it should minimize complexity, should serve a focused purpose and should minimize inter-service communication. Importantly, each microservices should be built as a PRODUCT!\"","id":9,"section":"posts","tags":["API Design","MicroServices"],"title":"Microservices - Design Principle","uri":"https://neerajsidhaye.com/posts/api/designprinciple/"},{"content":"This post describes basics of\n SSE concepts SSE use cases How does SSE work Message Formats SSE code on Client side and Server side SseEmitter connection keep alive time Auto Re-connect mechanism  SSE Concepts  Server Sent Events are the events ( data ) sent from server to the client over HTTP connection.\nThis connection is one directional connection from server to client. Meaning that, once the client connects to server, then there after server will send any real-time notifications generated on the server side, to the client.\nClient can be mobile app or browser based app, or any client that support HTTP Connection.\nSSE use cases You would have seen SSE use cases around you in day to day life\n Continuous update about train time notifications on the display panel on the platform. Continuous Rolling of Stock updates. Real time counter increment of your social media \u0026lsquo;likes\u0026rsquo; icon and could be more\u0026hellip;  How does SSE work Client initiates a connection to server over http, this can be done by client calling a rest end point on the server, in return, the response should have content-type header values as text/event-stream\nThis tells the client, that a connection is established and stream is opened for sending events from the server to the client.\nIn the browser you have a special object called, EventSource, that handles the connection and converts the responses into events.\nMessage-Formats SSE only supports text data. Meaning, server can only send text data to the client.\nBinary streaming, while possible, is inefficient with SSE. In that case, WebSocket would be good choice for binary data transfer.\nSSE code - Client side and Server side Client Side Code EventSource object is the core object supported by browser. To open a connection to the server, client will need to instantiate EventSource object.\n1  const eventSource = new EventSource(\u0026#39;http://localhost:8080/subscribe/\u0026#39;);   Browser sends this GET request with accept header text/event-stream.The response to this request, must contain header content-type with value text/event-stream and response must be encoded with UTF-8.\nTo process these events in the browser an application needs to register a istener for the message event.\nThe property data of the event object contains the message\n1 2 3 4  eventSource.onmessage = event =\u0026gt; { const msg = JSON.parse(event.data); // access your attributes from the msg. };   Client api supports certain events like open and error. Open event occurs as soon as 200 response is received by client for /subscribe GET call. Error event is received by client, when there is any network error or server terminates the connection.\nServer Side Code Http Response to the above GET request on /subscribe end point must contain the Content-Type header with the value text/event-stream.\nSpring Boot supports SSE by providing SseEmitter object. It was introduced in spring version 4.2 ( spring boot 1.3 ).\nCreate a spring boot application from start.spring.io and select web as dependency.\nYou can have a controller with rest end point GET with /subscribe allows client to establish connection.\nAnother rest end point POST with /event allows us to submit new events on the server. This POST with /events or similar end point, can be called from any other server side component to send real time notification.\nThis /event end point, will then send event to connected clients.\nEach client connection is represented with it\u0026rsquo;s own instance of SseEmitter.\nOne limitation with spring SSE is , it does not give you tools to manage these SseEmitter instances. So, for this example, I have used a list that stores SseEmitter objects and release objects on errors, completion or timeout scenarios.\nSseEmitter object is created as below\n1  SseEmitter emitter = new SseEmitter();   SseEmitter connection keep alive time By default, Spring Boot with the embedded Tomcat server keeps the SSE HTTP connection open for 30 seconds.We can override this 30 seconds via configurations.\nspring.mvc.async.request-timeout=50000\rthis entry will keep the HTTP connection open for 50 seconds. Alternatively, you can directly use SseEmitter constructor to pass this timeout value as below\nSseEmitter emitter = new SseEmitter(150_000L); //keep connection open for 150 seconds\rAuto Re-connect mechanism The nice thing about Server-Sent Events is that they have a built in re-connection feature. Meaning that, if the connection is dropped due to server error then client will automatically tries to re-connect after 3 seconds.\nThe browser tries to send reconnect requests forever until he gets a 200 HTTP response back.\nIt\u0026rsquo;s a browser feature to wait for 3 seconds and then automatically reconnect. This 3 seconds of time can be changed by the server by sending a new time value in the retry header attribute together with the message.\nA client can be told to stop reconnecting using the HTTP 204 No Content response code.\nDid you find this page helpful? Consider sharing it üôå ","description":"Server Sent Events - Concept, Use case, how SSE works, message formats, SSE code sample, SseEmitter connection keep alive time and Auto Reconnect mechanism","id":11,"section":"posts","tags":["Server Sent Events","SSE","EventSource"],"title":"Server Sent Events - Concepts","uri":"https://neerajsidhaye.com/posts/sse/sse/"}]